# ğŸ“„ Chatbot for PDF â€“ RAG-based Document Q&A using LLaMA & Groq

This is a lightweight Retrieval-Augmented Generation (RAG) agent that takes a PDF document, breaks it into chunks, indexes the chunks using FAISS, and answers user queries based on the document context using the LLaMA3 model deployed via Groq API.

---

## ğŸš€ Features

- âœ… Extracts text from PDF documents
- âœ… Splits text into meaningful chunks
- âœ… Builds a FAISS vector index for fast similarity search
- âœ… Uses Groq API with LLaMA3 to generate answers
- âœ… CLI-based (no FastAPI or web frontend)

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repo**

   ```bash
   git clone https://github.com/tibdewalchahak/Chatbot_for_PDF.git
   cd Chatbot_for_PDF
   ```
2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
3. **Set your Groq API key:**
   Create a .env file in the root directory:
   ```bash
   GROQ_API_KEY=your_groq_api_key_here
   ```
4. **Run the RAG agent**
   ```bash
   python main.py
   ```
   You'll be prompted to enter a PDF file path and then a query.

## ğŸ“ Project Structure
```bash
Chatbot_for_PDF/
â”œâ”€â”€ main.py               # Entry point for the agent
â”œâ”€â”€ .gitignore
â”œâ”€â”€ rag_utils.py           # FAISS index, search, and LLaMA3 answer generation
â”œâ”€â”€ pdf_utils.py           # PDF text extraction and chunking
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # (not included) Groq API key
â””â”€â”€ README.md
```

## ğŸ“Œ Example
```bash
Enter the path to your PDF file: ./docs/sample_resume.pdf
Ask a question: What technologies does the candidate know?
```
